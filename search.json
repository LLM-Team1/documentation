[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "StratMystiqPro Documentation",
    "section": "",
    "text": "Introduction and Project Overview\nIn this project our goal was to build a Large Language Model (LLM) application. Therefore we identified a use case to make use of a LLM. Based on that use case, we then build a business model canvas to define the foundation of our SaaS-start up.\nTogether with Mr. Kirenz we decided to first define our use case to then create a business model from there on. Our use case was based on the idea of finding a way to make business analysis quick and easy for a wide range of potential customers. After that we constructed the business model around this use case. You can read more about the use case identification and modelling of our Business Model Canvas here. For a more visual understanding of our startups’ next goals we created a strategy map showing the directions our start up could go in the future.\nOur solution takes the findings of our use case identification and transform them into a software as a service (SaaS) solution. This solution provides an analysis tool for our customers to fulfill our value propositions.\nWe are using a Retrieval Augmented Generation (RAG) pipeline to load and retrieve the needed information (coming from business reports) from our vector store. We encountered different obstacles on our way, therefore we decided to customize the basic RAG pipline to deal with image/ table recognition and at the same time improve answer precision by using a multi query approach.\nWe used multiple evaluation methods to evaluate the performance of our customized RAG. The main goal was here to identify the overall performance of our custom RAG compared to the basic RAG. At the same time we evaluated the best chunk size for both RAGs. The best solution was our custom RAG, using the chunk size of 900.\nWe also developed a user friendly frontend to enable our customers to navigate between their business reports, analyses, and comparisons. Focus here was especially on the presentation of the extensive information in the SWOT analyses.\nFinally we created a comprehensive manual on how to deploy our application and how to use our application.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction and Project Overview</span>"
    ]
  },
  {
    "objectID": "usecase.html",
    "href": "usecase.html",
    "title": "Usecase",
    "section": "",
    "text": "Our proposed use case is a Software-as-a-Service (SaaS) solution. This Saas is designed specifically for business strategy analysts within organizations, providing them with an advanced tool to enhance their competitor analysis tasks. The core functionalities of our platform include:\n\nReport Management: Users have the flexibility to upload their organization’s annual report, select from an existing repository, or choose from publicly available reports.\nSWOT Analysis Creation: The platform enables users to generate a SWOT (Strengths, Weaknesses, Opportunities, Threats) analysis directly from the selected annual report. This automated process aids analysts in identifying strategic factors critical for their company’s competitive positioning.\nChatbot Support: To further assist in the detailed examination of the reports, our solution incorporates a chatbot feature. This allows users to pose specific questions regarding the contents of the report, ensuring a comprehensive understanding of the analyzed data. This SaaS solution is tailored to support business strategy analysts by providing a coherent set of tools for efficient and in-depth competitive analysis, facilitating strategic decision-making processes within their organizations.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Usecase</span>"
    ]
  },
  {
    "objectID": "userPersona.html",
    "href": "userPersona.html",
    "title": "User Persona",
    "section": "",
    "text": "Demographic Data:\nName: Alex Schmidt\nAge: 35 years\nGender: Male\nPlace of residence: Stuttgart, Germany\nFamily status: Married without kids\nInterests: Cars, technology, business news, hiking, AI\nOccupation: Strategy analyst in the department for market and competition analysis at Mercedes Benz",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>User Persona</span>"
    ]
  },
  {
    "objectID": "userPersona.html#tasks-responsibilities",
    "href": "userPersona.html#tasks-responsibilities",
    "title": "User Persona",
    "section": "Tasks & Responsibilities:",
    "text": "Tasks & Responsibilities:\n\nCollect and analyze market data to identify trends and developments in the automotive industry\nAnalyze competitor data to identify strengths, weaknesses, opportunities and threats\nCreate comprehensive reports and presentations for executives to enable informed strategic decisions\nCollaborate with other departments to gather data and gain insights into various aspects of the market & the firm\nDevelop long-term strategic plans to strengthen the competitive position of Mercedes-Benz",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>User Persona</span>"
    ]
  },
  {
    "objectID": "userPersona.html#pains-problems",
    "href": "userPersona.html#pains-problems",
    "title": "User Persona",
    "section": "Pains & Problems:",
    "text": "Pains & Problems:\n\nTime-consuming data collection: Manual collection of market data & competitive information takes up a significant amount of working time\nRisk of information overload: The amount of data available carries the risk that Alex could overlook important trends and patterns\nDelays in reaction time: The time-consuming manual analysis leads to delays in reacting to current market developments and competitive changes\nLimited resources for in-depth analysis: Due to the time required, Alex cannot always perform the in-depth analysis required for comprehensive strategic planning\nLack of precision in data interpretation: Manual processing of data carries the risk of misinterpretation or human error, which could affect the accuracy and reliability of his analyses",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>User Persona</span>"
    ]
  },
  {
    "objectID": "bmc.html",
    "href": "bmc.html",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "",
    "text": "Value Proposition\nIt is our main goal to provide easy and fast access to branch insights. Being more precise, we aim to give our customers a wide overview of the market and their (direct) competitors. To achieve this goal we offer different features in our application, including the SWOT Analysis, the BCG Matrix, a Business Model Canvas and a short profile of the relevant competitor. Our customers choose which competitors they would like to analyze. They simply select or upload the annual report of a relevant competitor and start analyzing by using our features such as the SWOT Analysis. The tool consists of many different features to analyze the annual reports. We are planning to first publish the company profile/ summary, SWOT analysis, Business Model Canvas, and BCG Matrix, to then extend these features in the future to give our customers even more options to analyze the annual reports.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#customer-segments",
    "href": "bmc.html#customer-segments",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Customer Segments",
    "text": "Customer Segments\nAs our customer segments we decided to be focusing on companies in the automotive industry. This industry is currently extremely fast moving and the competition between those companies is on an all time high. One of the biggest reasons is the development of environmentally friendly vehicles and the rising competition by brands on the Asian market. This makes it very important for the affected companies to keep an eye on their competition and arising trends; making them the perfect customers for our analysis tool. More in detail, we identified strategic-competitor analysts in the automotive industry as our end users.\nIn the future we could extend our customer base to a variety of interesting customer segments. These customers could be firms in the field of investors, finance analysts or business consulting.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#customer-relationship",
    "href": "bmc.html#customer-relationship",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Customer Relationship",
    "text": "Customer Relationship\nTo build our first customer base we will step in personal contact with just a few companies in the automotive field. At the same time we are keeping this close relationship with our customers to fully understand them and their needs to optimize our products to serve them as efficiently as possible. We will also offer consulting to this customer segment to adjust or extend the features of the tool to their specific needs. Later we will make our product available to a wider range of customers and offer off the shelf software including a few basic analysis methods. This off the shelf software is the product we want to sell to a wider range of customers. To stay in touch we will set up an email newsletter to keep them posted on new feature releases and changes of our tool. This customer segment can then use our self-service to unlock these new features.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#channels",
    "href": "bmc.html#channels",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Channels",
    "text": "Channels\nDepending on the product we would either choose online marketing or direct sales. In case of the “off the shelf” software with no additional features we target the broader mass; meaning we are trying to reach as many customers with the same product. For our customer specific products, tailored to a more specific need on the customer side, we approach companies in a more direct sales kind of style. We expect to make more money per sale on the customer specific software, since we price the specifications and consulting services. That allows us to use this more expensive way of customer channel.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#key-partners",
    "href": "bmc.html#key-partners",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Key partners",
    "text": "Key partners\nAs our key partners we identified providers of corporate and financial data. In the beginning we will simply use the public annual reports of well known companies and let our customers upload their own data to our application. In the future we want to extend this function to also offer exclusive corporate and financial data on our application. This data will be brought in by the mentioned provider firms.\nAnother important partner is a marketing agency with experience in this field. With this partner we can get automotive companies to know us and our services.\nFacing the challenge of the groundedness and quality of the data provided by us we need auditing firms to ensure high quality of the data provided by our application.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#key-activities",
    "href": "bmc.html#key-activities",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Key activities",
    "text": "Key activities\nOne of our most important activities is software development. Especially in the beginning it is key to improve and extend the features of our product. Starting with our main feature, the SWOT matrix, we need to introduce more features and more ways to analyze the competition and market. Also the maintenance and updating of the database is a key activity. Another important activity is customer support. We want to help our customers with their problems -making it easy to reach out to us, which makes it easier for us to understand our customer needs, improve the product, and finally make our customers happy.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#key-resources",
    "href": "bmc.html#key-resources",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Key resources",
    "text": "Key resources\nThe most important Resource in our startup is the software developers. They ensure the quality and functionality of our product. Additional to that we need the hardware for our employees.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#cost-structure",
    "href": "bmc.html#cost-structure",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Cost structure",
    "text": "Cost structure\nOur Cost structure mainly consists of fixed cost for employee salaries for product development, maintenance, and consulting services. We also need to pay licenses for the commercial use of (development) software as fixed costs. At the same time we need to attract new customers, resulting in marketing expenses. For variable costs we pay for every API calls to OpenAI, made by our customers.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "bmc.html#revenue-streams",
    "href": "bmc.html#revenue-streams",
    "title": "Business Model Canvas and Use Case Identification",
    "section": "Revenue streams",
    "text": "Revenue streams\nFor our SaaS business model, our revenue stream is structured around several key components. Firstly, we offer licensing of our software tool, allowing customers to gain access to our platform and its basic functionalities. Secondly, we provide subscription-based access to our SaaS solution, offering different tiers or plans that unlock additional features and capabilities based on the customer’s needs and usage requirements. This subscription model ensures recurring revenue as customers continue to utilize our platform over time.\nIn addition to subscriptions, we offer maintenance and support services to ensure that our customers receive ongoing assistance, updates, and troubleshooting to keep their software running smoothly. This component not only enhances customer satisfaction but also provides an additional revenue stream through service contracts or subscription add-ons.\nMoreover, we differentiate ourselves by offering consulting services to tailor our software to the specific needs and requirements of our customers. Our team of experts works closely with clients to understand their business processes, customize the software accordingly, and provide training and guidance for optimal utilization. These consulting services serve as a valuable revenue stream, allowing us to provide personalized solutions while generating additional income beyond the software subscription fees.\nOverall, our revenue stream encompasses a combination of software licensing, subscription-based access, maintenance and support services, and consulting offerings, providing a comprehensive and sustainable approach to monetizing our SaaS business model.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Business Model Canvas and Use Case Identification</span>"
    ]
  },
  {
    "objectID": "strategyMap.html",
    "href": "strategyMap.html",
    "title": "Our Strategy Map",
    "section": "",
    "text": "Our strategy map serves as the blueprint for our journey toward success in the competitive tech landscape. With a clear focus on key areas, we aim to strategically position ourselves for sustainable growth and innovation. By outlining actionable steps across financial, customer, internal process, and learning and growth domains, we pave the way for achieving our organizational objectives with purpose and clarity.\n\n\n\nStrategy Map\n\n\nFinancial\nTo drive our financial success, we focus on optimizing revenue streams and ensuring profitability. By monitoring monthly and yearly revenue, as well as profit margins, we gauge our financial health and make informed decisions to fuel growth. Our commitment to financial sustainability underscores our dedication to long-term success and resilience in the market.\nCustomer\nOur customers are at the core of everything we do. Therefore, we prioritize their satisfaction and loyalty through exceptional experiences and responsive support. By minimizing customer acquisition costs and maximizing retention rates, we cultivate a loyal customer base that serves as advocates for our brand. Our relentless pursuit of customer-centricity drives our success and growth in the competitive tech industry.\nInternal Process\nEfficient internal processes are the backbone of our operational excellence and product innovation. Thus, we focus on streamlining workflows, improving product quality, and enhancing data operations. Through continuous iteration and collaboration, we ensure that our team remains agile, responsive, and innovative in delivering cutting-edge solutions to our customers.\nLearning and Growth\nInvesting in the growth and development of our team is paramount to our success. Therefore, we prioritize training sessions, promote satisfaction, and foster a culture of innovation and openness. By empowering our team to explore new ideas and technologies, we drive continuous improvement and maintain our competitive edge in the rapidly evolving tech landscape. Our commitment to learning and growth propels us forward on our journey toward excellence.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Our Strategy Map</span>"
    ]
  },
  {
    "objectID": "valueProposition.html",
    "href": "valueProposition.html",
    "title": "Value Proposition",
    "section": "",
    "text": "Customer Segment",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Value Proposition</span>"
    ]
  },
  {
    "objectID": "valueProposition.html#customer-segment",
    "href": "valueProposition.html#customer-segment",
    "title": "Value Proposition",
    "section": "",
    "text": "Gains:\n\nDevelop well-informed, mature strategies based on comprehensive market and competitor insights.\nAchieve a good understanding of both their own company and competitors, facilitating strategic positioning and advantage.\n\n\n\nPains:\n\nTime-consuming analysis and synthesis of annual reports from their own and competitor companies.\nDifficulties in the complete recording of all relevant data due to information overload and manual recording processes.\nSignificant time investment required to prepare detailed, actionable analyses.\n\n\n\nCustomer Jobs:\n\nEfficiently create detailed analyses and evaluations of market and competitor data.\nDerive and develop robust strategies based on comprehensive analyses and evaluations.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Value Proposition</span>"
    ]
  },
  {
    "objectID": "valueProposition.html#product-segment",
    "href": "valueProposition.html#product-segment",
    "title": "Value Proposition",
    "section": "Product Segment",
    "text": "Product Segment\n\nGain Creators:\n\nOffers a streamlined process for strategy development based on data-driven insights and benchmarks, saving valuable time.\nProvides a better understanding and classification of the company within the market, enabling strategy adjustments.\n\n\n\nPain Relievers:\n\nTailors to individual analyst needs, allowing for simultaneous strategy and analysis creation with less effort and more precision.\nFacilitates a more efficient, accurate analysis of both the user’s own data and competitor information, reducing the risk of oversight and misinterpretation.\n\n\n\nProduct and Services:\n\nAdvanced analysis tools for in-depth examination of own and competitor data, utilizing AI for enhanced accuracy and insight.\nComprehensive preparation of evaluations and analysis, including SWOT, to underpin strategic decision-making.\nSupport in the development of strategic approaches, ensuring they are informed by the latest, most relevant market data.",
    "crumbs": [
      "Business Relevance",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Value Proposition</span>"
    ]
  },
  {
    "objectID": "RAGpipeline.html",
    "href": "RAGpipeline.html",
    "title": "RAG Pipeline",
    "section": "",
    "text": "Introduction to Retrieval Augmented Generation (RAG)\nRetrieval-Augmented Generation (RAG) represents a significant advancement in the field of natural language processing (NLP) by combining the strengths of large language models (LLMs) with specific knowledge stored in external databases. (Li et al. 2022) They are particularly useful for knowledge-intensive Natural Language Processing (NLP) tasks (Lewis et al. 2020) and thus have been applied to various tasks including dialogue response generation, machine translation, and other generation tasks. (Li et al. 2022)\nAs the focus of our project is to generate and compare SWOT Analyses, which is a complex generation task, our main goal was to implement a RAG pipeline that is capable of generating factual and relevant SWOT Analyses using the companies annual report as the knowledge source. At the beginning of the project we explored basic RAG pipelines and then started to implement our own pipeline to suit our needs.",
    "crumbs": [
      "RAG System",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RAG Pipeline</span>"
    ]
  },
  {
    "objectID": "RAGpipeline.html#rag-pipelines",
    "href": "RAGpipeline.html#rag-pipelines",
    "title": "RAG Pipeline",
    "section": "RAG Pipelines",
    "text": "RAG Pipelines\n\nLangchain Base RAG\nThe first RAG pipeline we explored was build using the open-source library Langchain. The pipeline utilized the standard Langchain document loaders, text splitters and RetrievalQA chain. The code below is an extract from our first RAG pipeline. The code for the full pipeline can be viewed in the RAG-Prototype folder of the StratMystiqPro repository.\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import RetrievalQA\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\n\n\nopenai.api_key = os.environ['OPENAI_API_KEY']\nembedding_function = OpenAIEmbedding\n\nclient = chromadb.HttpClient(host=\"localhost\", port='8000')\ndb = Chroma(client=client,\n            collection_name=\"annual-reports\",\n            embedding_function=embedding_function)\n\nllm_name = \"gpt-3.5-turbo\"\nllm = ChatOpenAI(model_name=llm_name, temperature)\n\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't make up an answer. Use five sentences maximum. Keep the answer as concise as possible.\nContext: {context}\nQuestion: {question}\nHelpful Answer:\"\"\"\n\nQA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=db.as_retriever(),\n    return_source_documents=True,\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n\nquestion = \"What cars does Mercedes Benz produce?\"\n\nresult = qa_chain({\"query\": question})\nWe started experimenting with the Langchain pipeline and while it returned some relevant results, we found that the pipeline struggled to return relevant and factual information when the question was more complex or asked for specific numbers. We tried to identify the cause of the issue and identified three areas that we believed could be causing the issue:\n\nThe original document was not being split into relevant sections or the sections only contained partial information.\nA lot of relevant information is stored in tables and images, which the pipeline is not able to extract.\nThe question that was asked might not include the correct vocabulary or context to retrieve the relevant chunks.\n\nTo continue with our RAG pipeline development, we decided to look at current literature and their approaches to RAG pipelines.\n\n\nCustom RAG Pipeline\nDuring our research we came across the concept of advanced RAG. Advanced RAG is an evolution of the base or Naive RAG, designed to overcome its limitations through targeted improvements. In Advanced RAG, the focus is on refining the retrieval process with pre-retrieval and post-retrieval strategies as well as improving the document indexing. (Gao et al. 2023)\nWe decided to follow the Advanced RAG approach of Gao et al. and implement our own custom RAG pipeline. The three areas that we implemented for our custom RAG pipeline are:\n\nDocument Ingestion\n\nTable Extraction and Processing\nText Chunking\n\nPre-Retrieval\n\nQuery Expansion\nQuery Reformulation\n\nPost-Retrieval\n\nDocument Filtering\nRelevance Checking\n\n\nThe following image shows how the base RAG pipeline and the custom RAG pipeline differ. The orange boxes represent the areas where we implemented our own custom solutions.\n\n\n\nRAG Pipeline | Adapted from (Gao et al. 2023)\n\n\n\nDocument Ingestion\nIn the document ingestion phase, we implemented a custom solution to extract and process the relevant information from the annual reports. We noticed that a lot of relevant information was stored in tables and images, which the base RAG pipeline was not able to extract.\n\nTable Extraction\nWe first focused our attention on extracting the relevant information from the tables in the annual reports. We initially hoped that PDF files contain metadata that would identify the tables, but that is not the case. Through our research we came across multiple python libraries that claim to be able to identify and extract tables from PDF files. We tested the libraries camelot-py, tabula-py and pyMuPDF and found that none of them were perfect at identifying and extracting tables from the annual reports. However, pyMuPDF seemed to be the most accurate and therefore we decided to use it for our table extraction process.\nThe following code shows how we used pyMuPDF to identify and extract the tables from the annual reports.\nimport fitz\nimport uuid\nimport os\n\n# Load the annual report\ndoc = fitz.open(report_filepath)\n    for page in doc:\n        table_data = page.find_tables(\n                        vertical_strategy=\"text\",\n                        horizontal_strategy=\"lines\"\n                        )\n        if len(table_data.tables) &gt; 0:\n\n            # Margin in points (2 cm)\n            margin = 56.7\n\n            # Scaling factor to increase resolution\n            scale = 2\n\n            # Applying the scaling factor\n            matrix = fitz.Matrix(scale, scale)\n\n            for table in table_data:\n                # Expanding bounding box with margin\n                expanded_bbox = (\n                    max(table.bbox[0] - margin, 0),  # left\n                    max(table.bbox[1] - margin, 0),  # top\n                    min(table.bbox[2] + margin, page.rect.width),  # right\n                    min(table.bbox[3] + margin, page.rect.height)  # bottom\n                )\n\n                # Cropping the page to the expanded bounding box\n                rect = fitz.Rect(expanded_bbox)\n                cropped_table = page.get_pixmap(matrix=matrix, clip=rect)\n\n                # Checks if correct directory exists\n                if not os.path.exists(f\"./filestore/{report_id}\"):\n                    os.makedirs(f\"./filestore/{report_id}\")\n\n                # Saving the cropped table as a JPG\n                table_id = str(uuid.uuid4())\n                cropped_table.save(f\"./filestore/{report_id}/{table_id}.jpg\")\nThe screenshots of the tables can then be used to extract the relevant information from the tables. We decided to try AWS Textract and OpenAI’s Vision API to extract the relevant information from the tables. We found that OpenAI’s Vision API was more adaptable in extracting the relevant information from the tables as we could specify the output format and the specific information we wanted to extract.\nTo use the Vision API, we also had to provide a prompt to the API that specifies the information we want to extract and the output format. This required a number of prompt iterations to get a reliable and accurate output. The initial prompt and the final prompt we used are shown below:\nInitial Prompt:\ntable_extract_prompt_template = \"\"\"Return the complete table content in JSON format. In the JSON also include a short description of the tables. Use the following as a template:\n{\"tables\": [\n   {\n        \"title\": \"Forschung und Entwicklung\",\n        \"description\": \"Forschung und Entwicklung\",\n        \"unit\": \"in Millionen €\",\n        \"table_data\": [...]\n   },\n   {...}\n   ]\n}\nDO NOT RETURN ANYTHING ELSE!\"\"\"\nFinal Prompt:\ntable_extract_prompt_template = \"\"\"Return the complete table content in JSON format, structured to accurately represent both main and sub-data entries. The JSON should include a short description of the tables. If the table includes hierarchical data, such as a total figure with underlying subdivisions, ensure to represent this relationship in the JSON structure.\n\nFor tables with year-wise data:\n- Include main data entries with their corresponding sub-data as nested entries.\n- Clearly label data for each year.\n\nFor tables without year-wise data:\n- Adjust the structure to suit the table's format, still capturing any hierarchical data relationships.\n\nIn all cases, do not calculate or infer values. Only include data that is clearly visible and legible in the table. Do not make up or estimate data.\n\nUse the following template for tables with hierarchical year-wise data:\n\n{\n  \"tables\": [\n    {\n      \"title\": \"Forschung und Entwicklung\",\n      \"description\": \"Forschung und Entwicklung\",\n      \"unit\": \"in Millionen €\",\n      \"table_data\": [\n        {\n          \"row_description\": \"Total Earnings\",\n          \"data_by_year\": {\n            \"2021\": \"total for 2021\",\n            \"2022\": \"total for 2022\"\n          },\n          \"sub_data\": [\n            {\n              \"sub_row_description\": \"Subdivision 1\",\n              \"data_by_year\": {\n                \"2021\": \"data for 2021\",\n                \"2022\": \"data for 2022\"\n              }\n            },\n            // Additional subdivisions can be added here\n          ]\n        },\n        // Additional main rows can be added here\n      ]\n    },\n    // Additional tables can be added here\n  ]\n}\n\nAdapt the structure for tables without year-wise data or hierarchical relationships as needed.\n\nDO NOT RETURN ANYTHING ELSE!\n\"\"\"\nThe whole process can also be seen in the following image:\n\n\n\nTable Extraction Process\n\n\n\n\nText Extraction\nWe didn’t implement a custom solution for text extraction as we found that the Langchain Recursive Character Text Splitter did a good job at splitting the text into chunks. We did however define a list of custom separators that ensured that the text is not split in the middle of a sentence. We declared the separators as follows:\nseparators=[\"\\n\\n\", \"(?&lt;=\\. )\"]\nThis means that when the chunk size is reached, the text will be split at either the next paragraph or the next sentence.\nWhich brings us to the question of the ideal chunk size. We couldn’t find any literature that specified the ideal chunk size for RAG pipelines, so we decided to experiment with different chunk sizes ranging from 500 to 1000 characters. The evaluation of the different chunk sizes can be found in the RAG Evaluation section.\n\n\n\nPre-Retrieval\nThe pre-retrieval phase focuses on refining the query to improve the retrieval process. The goal of refining the query is to align the semantics of the query with the semantics of the documents. (Wang, Yang, and Wei 2023) A promising concept for this is GAR (Generation Augmented Retrieval), which is described in the paper: GAR meets RAG for Zero-Shot IR. The idea is to generate additional context for the query to improve the retrieval process. This can be achieved by replacing words with better synonyms, expanding the query with related words or reformulating the query to cover slightly different aspects of the same topic. (Arora et al. 2023)\nLike Arora et al., we are utilizing OpenAI LLMs to generate additional queries for the retrieval process. We didn’t use the Rewriting Prompt that Arora et al. created, but instead used their prompt as guidance to create our own use case specific prompt. The prompt we used is shown below:\nprompt_template = \"You are a professional annual business report writer. Analyse the users question and return three questions that are similar but use business vocabulary that can be found in annual business reports. Also think about being more specific or broader in the questions. Return them in JSON format.\"\nThe following example shows the input question and the generated questions that will be used to retrieve additional context.\n# Users question\nquestion = \"What cars does Mercedes Benz produce?\"\n\n# Generate additional questions\nadditional_questions = {\n    \"q1\": \"What competitive advantages do Mercedes-Benz's product offerings possess in the luxury automotive segment?\",\n    \"q2\": \"How do the core competencies of Mercedes-Benz contribute to its market positioning within the automotive industry?\",\n    \"q3\": \"What are the key product features that differentiate Mercedes-Benz in the premium vehicle category?\"\n}\n\n\nPost-Retrieval\nThe post-retrieval phase focuses on filtering and evaluating the retrieved documents to ensure that only relevant information is passed to the LLM to generate the final answer. Both Gao et al. and Arora et al. proposed a similar approach to the post-retrieval phase. They suggest that the documents should be filtered based on their relevance then re-ranked and finally summarized/compressed. (Gao et al. 2023) (Arora et al. 2023)\nWe evaluated the three proposed steps and noticed that another step is required to ensure that the documents are relevant. When querying for chunks with different but similar/related questions, the list of all retrieved chunks ended up containing several duplicates. As this would lead to unnecessary computation and cost, we decided that the first step of the post-retrieval phase should be to filter out the duplicates.\nAfter that, we implemented the relevance check for the chunks. Arora et al. did publish their relevance check prompt, however it turned out to be impractical for our use case. Their prompt was designed to evaluate all retrieved chunks at once, ranking them with a score from 1 to 5. This proofed to be impractical for us for three reasons:\n\nThe number of retrieved chunks together with their length maxed out the input limit of the GPT-4-Turbo model. This resulted in the model not being able to evaluate all chunks at once. Meaning that the documents couldn’t be scored based on all other chunks.\nThe complex query resulted in a longer processing times, adding significant and unpredictable delays to the RAG pipeline.\nThe very high token usage for the evaluation prompt resulted in a high cost for the evaluation process.\n\nBased on these reasons, we decided to create our own relevance check prompt that evaluates each chunk individually. Our prompt is designed to evaluate the relevance of the chunk based on the original question and the chunk itself. The prompt is shown below:\nprompt_template = \"You are a professional business analyst. Analyse the given document and see if it contains information that is useful for answering the users question. Be very strict!. ONLY REPLY WITH YES OR NO. No need to be polite.\"\nBased on the relevance check, we then removed all chunks that were not relevant. Leaving us with a list of relevant chunks.\nThe next step in the model that Gao et al. suggested was to re-rank the documents. We decided to skip this step as the chunks were already ranked by the Max-Marginal-Relevance (MMR) algorithm that was used to retrieve the chunks and this additional step would once again be very token intensive. The MMR algorithm ranks the chunks based on their relevance to the query and their similarity to the other chunks. As we append the chunks found for the additional queries to the chunks found for the original query, we ensure that according to the MMR algorithm the most relevant chunks for the original question are at the top of the list.\nThe final step in the post-retrieval phase is to summarize/compress the chunks. While we would have liked to implement this step, the approaches named by Gao et al. were all based on custom trained information extraction and compression models that we didn’t have access to. To avoid more cost by having the LLM summarize the chunks, we decided to leave the chunks as they are and let the LLM generate the final answer based on the list of relevant chunks.\n\n\n\n\nArora, Daman, Anush Kini, Sayak Ray Chowdhury, Nagarajan Natarajan, Gaurav Sinha, and Amit Sharma. 2023. “Gar-Meets-Rag Paradigm for Zero-Shot Information Retrieval.” https://doi.org/10.48550/ARXIV.2310.20158.\n\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, et al. 2023. “Retrieval-Augmented Generation for Large Language Models: A Survey.” https://doi.org/10.48550/ARXIV.2312.10997.\n\n\nLewis, Patrick, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, et al. 2020. “Retrieval-Augmented Generation for Knowledge-Intensive Nlp Tasks.” https://doi.org/10.48550/ARXIV.2005.11401.\n\n\nLi, Huayang, Yixuan Su, Deng Cai, Yan Wang, and Lemao Liu. 2022. “A Survey on Retrieval-Augmented Text Generation.” https://doi.org/10.48550/ARXIV.2202.01110.\n\n\nWang, Liang, Nan Yang, and Furu Wei. 2023. “Query2doc: Query Expansion with Large Language Models.” https://doi.org/10.48550/ARXIV.2303.07678.",
    "crumbs": [
      "RAG System",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>RAG Pipeline</span>"
    ]
  },
  {
    "objectID": "RAGevaluation.html",
    "href": "RAGevaluation.html",
    "title": "RAG Evaluation",
    "section": "",
    "text": "Fundamental Goals of Evaluation",
    "crumbs": [
      "RAG System",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>RAG Evaluation</span>"
    ]
  },
  {
    "objectID": "RAGevaluation.html#ragas-evaluation",
    "href": "RAGevaluation.html#ragas-evaluation",
    "title": "RAG Evaluation",
    "section": "RAGAS Evaluation",
    "text": "RAGAS Evaluation\nFinally we ended up using the RAGAS framework (“Metrics  Ragas” n.d.) since this made it easy to extract the evaluation results in an excel file to later compare it with our human centered evaluation approach. Following you we see the results of our evaluation using the RAGAS framework.\nIn the following we compare the overall performance of the Base RAG and our Custom RAG, using the different chunk sizes. We found that the best chunk size for the Base RAG is 700; while the best chunk size for our Custom RAG is a size of 900.\n\n\n\nComparison of overall RAGAS Evaluation\n\n\nIn this diagram we can see that our Custom RAG has an overall lower Context Precision. As expected this is caused by our query rewriting. At the same time we notice that the answer relevance is higher; meaning we archived our goal to improve the answer relevance by rewriting the initial question. Overall our Custom RAG at a chunk size of 900 outperformed the base RAG at a chunk size of 700.",
    "crumbs": [
      "RAG System",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>RAG Evaluation</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/backendArchitecture.html",
    "href": "BackendArchitecture/backendArchitecture.html",
    "title": "Requirements and Tech Stack",
    "section": "",
    "text": "Backend Requirements\nAt the beginning of the project, we were trying to decide what technologies and architectures we should use to build our system. To make these decisions, we decided to to define the requirements that the system should meet from a technical standpoint. Seeing that the goal of this project is to build a prototype for a SaaS tool, the backend should be designed to meet a number of requirements. These have been grouped into the following categories:",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Requirements and Tech Stack</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/backendArchitecture.html#backend-requirements",
    "href": "BackendArchitecture/backendArchitecture.html#backend-requirements",
    "title": "Requirements and Tech Stack",
    "section": "",
    "text": "Scalable\nThe system should be designed to handle multiple number of users and tasks at any time without impacting performance.\n\nHandle multiple different Users at any time:\n\nProcess a variety of reports simultaneously.\nProvide answers to user queries efficiently.\n\nAllow easy horizontal or vertical scalability:\n\nThe system should be capable of scaling out (adding more nodes to the system) and scaling up (adding more power to existing nodes) as necessary, without any service interruption.\n\n\n\n\nResource Efficient\nOptimizing the use of resources is crucial for maintaining a cost-effective and high-performing system.\n\nMinimize API-Calls to OpenAI and other external services:\n\nReduce the frequency and volume of API requests to avoid unnecessary costs and to maintain system responsiveness.\n\nOnly regenerate responses if requested by a User:\n\nCache and reuse responses where possible to avoid redundant computations.\n\n\n\n\nAdaptable\nThe system should be flexible to accommodate changes and the addition of new features.\n\nAllow Users to upload reports from several business sectors:\n\nSupport a diverse range of report formats and contents to cater to different industry needs.\n\nIt should be easy to add features to the tool without major code changes:\n\nDesign the architecture to be modular, allowing new features to be added with minimal changes to the core codebase.\n\n\n\n\nSecure\nSecurity is a top priority to protect user data and ensure trust in the system.\n\nUser Log-In should be secure and follow industry standards:\n\nImplement authentication mechanisms that meet current security best practices.\n\nEnsure User Data is separated and protected from unauthorized access:\n\nApply strict access controls and data isolation to ensure that user data is not exposed to unauthorized entities.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Requirements and Tech Stack</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/backendArchitecture.html#tech-stack",
    "href": "BackendArchitecture/backendArchitecture.html#tech-stack",
    "title": "Requirements and Tech Stack",
    "section": "Tech Stack",
    "text": "Tech Stack\nBased on the requirements defined above, we decided to use the following technologies to build the backend of the system. The following sections will provide a brief overview of each technology and the reasons for choosing them.\n\nPython\nThe backend of the system is built using Python, some of the reasons for choosing Python are:\n\nEase of Use:\n\nAll team members have experience working with Python, making it easy for all team members to actively contribute to the project.\n\nNumerous Opensource Libraries:\n\nPython has a rich ecosystem of libraries and tools ranging from backend frameworks to machine learning libraries such as Flask and Langchain.\n\n\n\n\nFastAPI\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python. The reasons for choosing FastAPI are:\n\nPerformance and Asynchronous Request Handling:\n\nFastAPI is built on top of Starlette for web routing and Pydantic for data validation, this makes it more performant than other Python web frameworks such as Flask.\nIt supports asynchronous request handling natively, which is crucial for handling multiple requests simultaneously where long-running tasks are expected.\n\nAutomatic API Documentation:\n\nFastAPI automatically generates API documentation based on the code, which makes it easier to maintain and update the documentation.\nIt provides a built-in interactive API documentation (Swagger UI) which makes it easier to test and debug the API. Without the need for additional tools such as Postman.\n\n\n\n\nDocker\nDocker is a platform for developing, shipping, and running applications. The reasons for choosing Docker are:\n\nConsistent Development Environment:\n\nDocker allows us to create a consistent environment for development as it greatly reduces the number of possible errors when working with different platforms (Mac and Windows).\nDatabases and other services can be run as containers, which makes it easier to set up and tear down the development environment quickly.\n\nEasy Deployment:\n\nDocker containers can be deployed to any platform that supports Docker, which makes it easier to deploy the system to different cloud providers.\nServices can be scaled horizontally by running multiple containers of the same service.\n\n\n\n\nMySQL\nTo store user, report and analysis data, we decided to use a relational database. The reasons for choosing MySQL are:\n\nExperience:\n\nAll team members have experience working with MySQL, making it easier for all team members to actively contribute to the project.\n\nScalability:\n\nShould the need arise, MySQL can be scaled horizontally by using sharding or clustering to handle a large number of users and reports.\n\n\n\n\nChromaDB\nChromaDB is an open-source vector store that is designed to store and retrieve vector embeddings. The reasons for choosing ChromaDB are:\n\nNatively Supported by Langchain:\n\nChromaDB is natively supported by Langchain modules and thus requires minimal configuration to build initial prototypes.\n\nDocumentation and Community:\n\nChromaDB has a rich documentation and an active community which makes it easier to get help and support when needed.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Requirements and Tech Stack</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html",
    "href": "BackendArchitecture/Datamodel.html",
    "title": "Application Data Model",
    "section": "",
    "text": "Overview Diagram\nThe following diagram provides an overview of the data model, the relationships between the different entities as well as the relationship between the relational database and vector store.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#overview-diagram",
    "href": "BackendArchitecture/Datamodel.html#overview-diagram",
    "title": "Application Data Model",
    "section": "",
    "text": "Note\n\n\n\nThe diagram is a simplified version of the data model and thus does not represent the normalized entity relationship model that is implemented in the database. To learn about the implementation in the database, please refer to the Python Implementation section.\n\n\n\n\n\nData Model of StratMystiqPro",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#user",
    "href": "BackendArchitecture/Datamodel.html#user",
    "title": "Application Data Model",
    "section": "User",
    "text": "User\nThe User entity represents a user of the system. It is created when a user logs in to the system for the first time. The User entity has the following attributes:\n\nuser_id: (PK:UUID) A unique identifier for the user.\nusername: (String) The username of the user.\nemail: (String) The email address of the user.\nrole: (String) The role of the user, which can be either “admin” or “user”.\ncreated_at: (DateTime) The date and time when the user was created.\nupdated_at: (DateTime) The date and time when the user was last updated.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#report",
    "href": "BackendArchitecture/Datamodel.html#report",
    "title": "Application Data Model",
    "section": "Report",
    "text": "Report\nThe Report entity is the central entity of the system. It represents a report that a user uploads to the system. A Report by default is private and can only be accessed by the user who uploaded it. The User does have the option to make the report public. The Report entity has the following attributes:\n\nreport_id: (PK:UUID) A unique identifier for the report.\ntitle: (String) The title of the report.\nfilename: (String) The filename of the report.\nyear: (Integer) The year the report was published.\ncompany_id: (FK:UUID) The company identifier of the report. Foreign key to the Company entity.\nreport_public: (Boolean) A flag to indicate if the report is public or private.\ncreated_at: (DateTime) The date and time when the report was created.\nupdated_at: (DateTime) The date and time when the report was last updated.\ndeleted_at: (DateTime) The date and time when the report was deleted.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#company",
    "href": "BackendArchitecture/Datamodel.html#company",
    "title": "Application Data Model",
    "section": "Company",
    "text": "Company\nThe Company entity represents the company that the report is associated with. The Company entity has the following attributes:\n\ncompany_id: (PK:UUID) A unique identifier for the company.\nname: (String) The name of the company.\nindustry: (String) The industry of the company.\ncreated_at: (DateTime) The date and time when the company was created.\nupdated_at: (DateTime) The date and time when the company was last updated.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#analysis",
    "href": "BackendArchitecture/Datamodel.html#analysis",
    "title": "Application Data Model",
    "section": "Analysis",
    "text": "Analysis\nThe Analysis entity is the object that contains the results of the main feature of the system. It represents the analysis of a report that a user requests. Note that the Analysis entity is specifically not called SWOT Analysis, as the system is designed to be flexible and adaptable to accommodate new types of analysis in the future. The Analysis entity has the following attributes:\n\nanalysis_id: (PK:UUID) A unique identifier for the analysis.\nreport_id: (FK:UUID) Reference to the report that the analysis is associated with.\ncompare_report_id: (FK:UUID) If the analysis is a comparison analysis, this field will reference the report that was used for comparison.\ntype: (String) The type of analysis, currently supported are “swot” or “swot_comparison”.\ncontent: (Text) The content of the analysis, which is a JSON string that contains the results of the analysis.\ncreated_at: (DateTime) The date and time when the analysis was created.\nupdated_at: (DateTime) The date and time when the analysis was last updated.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#analysis-section",
    "href": "BackendArchitecture/Datamodel.html#analysis-section",
    "title": "Application Data Model",
    "section": "Analysis Section",
    "text": "Analysis Section\nThe Analysis Section entity represents a section of the analysis. It was introduced towards the end of the project to store intermediate results of the analysis. In case an analysis process is interrupted, the system can use the intermediate results to continue the analysis where it stopped. The Analysis Section entity has the following attributes:\n\npartial_result_id: (PK:UUID) A unique identifier for the partial result.\nanalysis_id: (FK:UUID) Reference to the analysis that the partial result is associated with.\nsection: (String) The section of the analysis, which can be “strengths”, “weaknesses”, “opportunities” or “threats”.\ncontent: (Text) The content of the partial result, which is a JSON string that contains the intermediate results of the analysis.\ncreated_at: (DateTime) The date and time when the partial result was created.\nupdated_at: (DateTime) The date and time when the partial result was last updated.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#screenshot",
    "href": "BackendArchitecture/Datamodel.html#screenshot",
    "title": "Application Data Model",
    "section": "Screenshot",
    "text": "Screenshot\nThe Screenshot entity is used to track and identify the screenshots that are taken of the reports. The Screenshots are either the identified tables or the cover page of the report. It is implemented in a way that allows all other types of screenshots to be added in the future. The Screenshot entity has the following attributes:\n\nscreenshot_id: (PK:UUID) A unique identifier for the screenshot.\nreport_id: (FK:UUID) Reference to the report that the screenshot is associated with.\nfilename: (String) The filename of the screenshot.\ntype: (String) The type of the screenshot, which can be “table” or “image”.\ndescription: (Text) A JSON string that contains the information extracted from the screenshot.\ncreated_at: (DateTime) The date and time when the screenshot was created.\nupdated_at: (DateTime) The date and time when the screenshot was last updated.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#job",
    "href": "BackendArchitecture/Datamodel.html#job",
    "title": "Application Data Model",
    "section": "Job",
    "text": "Job\nThe Job entity was originally introduced to track the status of the report ingestion. While developing the system, we realized that we need to track the status of many long-running task in the system. It also acts a Job-List for the Backend to process outstanding jobs. The Job entity has the following attributes:\n\njob_id: (PK:UUID) A unique identifier for the job.\nobject_id: (UUID) Reference to the object that the job is associated with. Currently supported are report_id, analysis_id or screenshot_id.\nobject_type: (String) The type of the object that the job is associated with. Currently supported are “report”, “analysis” or “screenshot”.\nuser_id: (FK:UUID) Reference to the user that the job is associated with.\nstatus: (String) The status of the job, which can be “pending”, “in_progress”, “completed” or “failed”.\npercentage: (Integer) The percentage of the job that has been completed. (Only supported in report_ingestion)\nrequest_date: (DateTime) The date and time when the job was requested.\ncompletion_date: (DateTime) The date and time when the job was completed.\ncreated_at: (DateTime) The date and time when the job was created.\nupdated_at: (DateTime) The date and time when the job was last updated.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/Datamodel.html#vector-store",
    "href": "BackendArchitecture/Datamodel.html#vector-store",
    "title": "Application Data Model",
    "section": "Vector Store",
    "text": "Vector Store\nIn the report ingestion process, the system extracts the text from the report, splits it into chunks and stores it in the vector store. The vector store is used to store the vector embeddings of the text, the text that was embedded, as well as metadata to identify the individual chunks. The Vector Store knows the following two entities:\n\nCollection\nThe Collection entity represents a group of vector embeddings. We currently only use one collection to store the embeddings of all reports. For future use cases, we planned on adding more collections to store embeddings of different types of data (Websites…) The Collection entity has the following attributes:\n\ncollection_id: (PK:UUID) A unique identifier for the collection.\nname: (String) The name of the collection.\ncreated_at: (DateTime) The date and time when the collection was created.\n\n\n\nChunk\nThe Chunk entity represents a single chunk of text that was embedded and stored in the vector store. The Chunk entity has the following attributes:\n\nchunk_id: (PK:UUID) A unique identifier for the chunk.\nvectors: (Array) An array of floats that represents the vector embeddings of the text.\ntext: (Text) The text that was embedded.\nmetadata: (JSON) A JSON string that contains metadata to identify the chunk.\n\nreport_id: (UUID) The report the chunk is associated with. Links to the Report entity in the relational database.\nchunk_type: (String) The type of the chunk, which can be “table” or “report_text”.\nextra_content: (JSON) Only used for “table” chunks. Contains the extracted table data.\npage_number: (Integer) The page number of the report where the chunk was extracted from.\n\n\n\n\n\nData Model of StratMystiqPro",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Application Data Model</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/PythonImplementation.html",
    "href": "BackendArchitecture/PythonImplementation.html",
    "title": "Backend Implementation",
    "section": "",
    "text": "Class Structure\nThis section will focus on the Python classes that were implemented to handle the business logic of the system. It should be noted that while it would have been ideal to implement a clean and consistent class structure from the beginning, we decided to let it evolve over time, as we were not sure about the exact implementation details of the RAG Pipeline.\nTherefore classes that represent the entities of the system such as User, Report, Analysis, etc. don’t contain any business logic and are only used to represent the data model of the system. They are needed to interact with the relational database using the SQLAlchemy ORM. As such, they are represented in our class diagram, but are not discussed in this section as their attributes are discussed in the data model section.\nFurthermore, certain areas of the system such as the implementation of the FastAPI endpoints are not programmed in a class-based structure, but rather in a function-based structure as recommended by the FastAPI documentation. The following sections will provide a brief overview of the relevant classes, their responsibilities and examples on how to use the classes.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Backend Implementation</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/PythonImplementation.html#class-structure",
    "href": "BackendArchitecture/PythonImplementation.html#class-structure",
    "title": "Backend Implementation",
    "section": "",
    "text": "Class Diagram\nThe following diagram provides an overview of the classes and their relationships. The diagram does not contain the FastAPI endpoints, and authentication logic as they are not implemented as classes. \n\n\nConfig\nThe Config class is responsible for loading environment variables, initializing the OpenAI API, the Chroma Vector Store, and the MySQL Database. It does this in its init method. The environment variables are loaded from a .env file or from the Docker environment, depending on the environment in which the application is running.\nThe Config class is used to manage the configuration of the application. It provides a centralized place to manage all configuration settings. This makes it easier to change settings and manage dependencies as they are all in one place.\nThe Config class is written as a Singleton class. The Singleton pattern is a design pattern that restricts the instantiation of a class to a single instance. This is important as the Config class is responsible for initializing several dependencies such as the database connections which should only be initialized once and shared across the application.\nThe following code snippet shows how to use the Config class in other parts of the application to access the configuration settings or dependencies such as the database connection.\nfrom config import Config\n\n# Instantiate the Config class\nconfig = Config()\n\n# Accessing the LLM Name for the OpenAI API\nopenai_api_key = config.LLM_NAME\n\n# Accessing the vector database client\ndb = config.chroma\n\n# Accessing the MySQL database session\nsession = config.mysql_db.get_session()\n\n\nDatabase\nThe Database class is responsible for managing the connection to the MySQL database. It provides methods to create the database and tables, should they not exist, and to get a session to interact with the database. It contains two important settings that might need to be changed depending on the load of the system.\n\npool_size - The number of connections to the database that are kept open at all times. This should be set to a value that is appropriate for the expected load of the system. Especially when the system is expected to handle a large number of concurrent report uploads, or SWOT analysis generation requests, this value should be increased, as these long-running tasks will keep their database connections open for the duration of the task.\nmax_overflow - The maximum number of connections that can be created above the pool_size. This setting comes into play when the pool is exhausted and all connections are in use. If the pool is exhausted and the number of connections is below the max_overflow value, new connections will be created. If the number of connections is above the max_overflow value, the application will wait for a connection to become available. This results in a longer response time for the user.\n\nThe direct usage of the Database class is limited to the Config class, which initializes the database connection and provides a method to get a session to interact with the database. Therefore, the following code snippets show how the Database class is used in the Config class and how the Config class can be used to access the database.\nfrom services.mysql_connector import Database\n\n# Instantiate the Database class with the database URL\ndb = Database('mysql+pymysql://user:password@localhost/db_name')\n\n# Initialize the database\ndb.init_db()\n\n# Get a new session and interact with the database\nsession = db.get_session()\nfrom config import Config\nfrom business_objects.user import User\n\n# Instantiate the Config class\nconfig = Config()\n\n# Get a database session\nsession = config.mysql_db.get_session()\n\n# Interact with the database to get a user\nuser = session.query(User).filter(User.id == user_id).first()\n\n\nChromaConnector\nThe ChromaConnector class is responsible for managing the connection to the Chroma Vector Store. In its init method, it initializes the connection to the Chroma Vector Store and creates the collection that is used to store the chunks for the annual reports, should it not exist.\nThe ChromaConnector class provides methods to get the current collection, the chromadb client, and to switch to a different collection. It also contains methods purely used for the development of the system, such as a method to delete all reports from the collection, or completely reset the collection.\nSimilar to the Database class, the direct usage of the ChromaConnector class is limited to the Config class, which initializes the Chroma Vector Store connection and provides a method to get the Chroma Vector Store client. Therefore, the following code snippets show how the ChromaConnector class is used in the Config class and how the Config class can be used to access the Chroma Vector Store.\nfrom services.chromadb_connector import ChromaConnector\n\n# Instantiate the ChromaConnector class with the Chroma Vector Store URL\nchroma = ChromaConnector(host=\"0.0.0.0\", port=8000, collection_name=\"annual-reports\")\nfrom config import Config\n\n# Instantiate the Config class\nconfig = Config()\n\n# Get the Chroma Vector Store client\ndb = config.chroma\n\n# Query the Chroma Vector Store\ndocs = db.max_marginal_relevance_search(str(query), k=5)\n\n\nBusinessAnalyst\nThe BusinessAnalyst class is the central class and component of the system. It is responsible for all the analyses that are performed on an annual report. It is also the class that contains the retrieval elements of our RAG-Pipeline. The reason for this is that all of the use-cases that require the generation of content, using the provided business reports, are related to the analysis of an annual report. Therefore, it made sense to implement that part of the RAG Pipeline in the BusinessAnalyst class.\nThe class is designed to interact with our database for data retrieval and storage, perform tasks such as similarity search, question reformulation, document evaluation, and generate SWOT analyses. It also contains the logic to compare SWOT analyses.\nThe class has to be initialized with the name of the company that should be analyzed, an OpenAI client, a database connection and the specific report-id. Should a comparison be required, the class also needs to be initialized with the report-id of the report that should be compared to the original report.\nThe following code snippet shows a few simplified examples of how the BusinessAnalyst class can be used:\nfrom services.business_analyst import BusinessAnalyst\nfrom config import Config\nimport openai\n\n# Instantiate the Config class\nconfig = Config()\n\n# Load supporting services from the Config class\nclient = openai.OpenAI(api_key=config.OPENAI_API_KEY)\ndb = config.chroma\n\n# Instantiate the BusinessAnalyst class\nanalyst = BusinessAnalyst(company_name=\"Mercedes Benz\",\n                          report_id='...',\n                          openai_client=client,\n                          db=db)\n\n# Answer a question about the company using the Annual Report\nquestion = \"What new products were launched in 2022?\"\nanswer = analyst.answer_question_with_annual_report(question=question)\n\n# Generate a SWOT analysis for the company\nswot = analyst.generate_swot_analysis()\n\n# Generate SWOT analysís summary\nsummary = analyst.generate_swot_analysis_summary(analysis_id='...')\nThe retrieval elements of the RAG-Pipeline are implemented in the following methods of the BusinessAnalyst class:\n\nreformulate_question(question: str, prompt_template=None) -&gt; List[str]\n\nThis method takes the original question as input and generates three reformulated questions that cover slightly different aspects of the original question. The prompt to achieve this is shown in the RAG-Pipeline section of the documentation.\nShould the original prompt that is provided not be sufficient, the prompt_template can be used to provide a custom prompt that is used to generate the reformulated questions.\n\n_similarity_search(query: str, k: int = 3, report_id=None) -&gt; List[Document]\n\nThis method takes a query as input and performs a similarity search on the annual reports in the Chroma Vector Store.\nThe method returns the k most relevant chunks using the Max-Marginal-Relevance Search feature of ChromaDB.\nThe method contains logic to ensure that only the chunks that are related to the selected report are returned and that if there are no chunks related to the report, the method returns an exception that the report does not exist in the Chroma Vector Store. See code excerpt below:\n\ndef _similarity_search(self, query, k=3, report_id=None):\n    \"\"\"\n    :param query: The query to search for\n    :param k: The number of documents to return\n    :param report_id: The report ID to filter the search\n    :return: [Document1, Document2, ...]\n    \"\"\"\n    ...\n    if len(self.db.get(where={'report_id': report_id})['ids']) == 0:\n        print('No chunks found for this report id.')\n        raise Exception('Report id does not exist in the database.')\n    else:\n        docs = self.db.max_marginal_relevance_search(\n                    str(query),\n                    k=k,\n                    filter={\"report_id\": report_id})\n        return docs\nevaluate_documents_for_use(documents: List[Document], question: str, prompt_template=None) -&gt; List[Document]\n\nThis method takes a list of documents and a question as input and evaluates if the documents are relevant to answer the question. It returns the curated list of documents that are relevant to answer the question.\nThe prompt to achieve this is shown in the RAG-Pipeline section of the documentation.\nShould the original prompt that is provided not be sufficient, or a special use-case requires a different prompt, the prompt_template can be used to provide a custom prompt.\nThe method contains the logic to replace the summary of a table, should on be included in the documents list, with the full content of the table. This way the table content is evaluated, and if relevant, included in the curated list of documents. The code excerpt below shows how this is achieved:\n\n...\nfor doc in documents:\n    try:\n        if doc.metadata['doc_type'] == 'Table':\n            doc_content = doc.metadata['doc_content']\n        else:\n            doc_content = doc.page_content\n    except AttributeError:\n        doc_content = doc\n\n    chat_completion = self.client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": prompt_template\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f'\"\"\"{doc_content}\"\"\"'\n                           f'Question: {question}',\n            }],\n            model=\"gpt-4-1106-preview\",\n        )\n\n    if 'No' in chat_completion.choices[0].message.content:\n        documents.remove(doc)\nreturn documents\nanswer_question_with_context(question: str, documents: List[Document], prompt_template=None, json_format=False) -&gt; str\n\nThis method takes a question and a list of documents as input and generates an answer to the question using the documents as context.\nThe method contains a standard prompt, but best results are achieved when a custom prompt is provided that is tailored to the specific use-case (e.g. SWOT analysis).\nThe method iterates over the documents and generates a messages object for the OpenAI API that contains the prompt and all the provided documents.\n\n\n\nGenerating a SWOT Analysis\nTo create a SWOT analysis, we decided to split the SWOT analysis into its four sections and then generated four different questions for each section. The questions were chosen to cover different aspects of each section. Each question is contained in its own method, and contains sub-questions that are used to retrieve extra context for the main question as well as a prompt that is tailored to the section of the SWOT analysis. The following code snippet is the method that tries to find the strengths that the company has through its brand and reputation:\n...\ndef identify_strengths_brand_reputation(self):\n    # Main- and sub-questions\n    question = f\"How has customer perception of {self.company_name} evolved, and what initiatives have been taken to enhance brand image?\"\n\n    self.temp_questions = [\n        f\"How has customer perception of {self.company_name} evolved, and what initiatives have been taken to enhance brand image?\",\n        f\"What products does {self.company_name} produce and how should customers perceive them?\"\n    ]\n\n    # Perform similarity search and build the documents list\n    for question in self.temp_questions:\n        self.temp_documents += self._similarity_search(\n                                question,\n                                k=5,\n                                report_id=self.report_id)\n\n    # Evaluate the documents for use\n    self.temp_documents = self.evaluate_documents_for_use(\n                            self.temp_documents,\n                            question)\n\n    # Answer prompt with instructions for generating the answer\n    answer_prompt = f\"\"\"\n    You are a professional business analyst. Analyse the given documents\n    and answer the users question. Your response will be used as part of a SWOT\n    matrix. Use as much of the documents as possible. If you don't find the\n    answer in the provided documents, indicate your lack of access to the\n    required information rather than hallucinating.\n\n    Step 1 - Identify up to four strengths in the brand reputation that allow\n             {self.company_name} to achieve or maintain positive customer\n             perception.\n\n    Step 2 - Describe the brand reputational strengths further and what\n             initiatives this company has taken to enhance this specific\n             strength. Use the information from the provided documents.\n\n    Step 3 - Reply in JSON format where the key is the main topic and the value\n             follows the following structure:\n            {{\n            \"strengths_brand_reputation\": [\n              {{\n                \"area\": \"...\",\n                \"description\": \"...\",\n                \"details\": {{\n                  \"stepsTaken\": \"...\",\n                  \"additionalNotes\": \"\"\n                }}\n              }},\n              {{\n                \"area\": \"...\",\n                \"description\": \"...\",\n                \"details\": {{\n                    ...\n                }}\n              }},\n              // More strategy areas...\n            ]\n            }}\"\"\"\n\n    # Answer the question with context\n    answer = self.answer_question_with_context(\n                self.temp_documents,\n                question,\n                answer_prompt,\n                json_format=True)\n\n    return json.loads(answer)\nSimilar methods exist for all other sections of the SWOT analysis. The JSON Output of the SWOT analysis is then combined into a single SWOT analysis and stored in the database. The main areas of each section of the SWOT analysis are then used to generate a summary of the SWOT analysis.\n\n\nComparing SWOT Analyses\n\n\n\n\n\n\nNote\n\n\n\nAs the comparison of SWOT analyses contains very similar logic and prompts to the generation of the SWOT analysis, this section does not contain any new code snippets. The full code can be found in the BusinessAnalyst class.\n\n\nTo compare two SWOT analyses, the BusinessAnalyst class contains a method that takes the two SWOT analyses as input and then compares one section at a time. The reason for this is that comparing multiple sections at once maxed out the input token limit of the OpenAI API.\nSimilar to the generation of the SWOT analysis, the comparison of the SWOT analyses has a specific prompt that clearly instructs the OpenAI API on how to compare the two SWOT analyses and what the expected output should look like. The full code can be found in the BusinessAnalyst class.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Backend Implementation</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/PythonImplementation.html#report-processing",
    "href": "BackendArchitecture/PythonImplementation.html#report-processing",
    "title": "Backend Implementation",
    "section": "Report Processing",
    "text": "Report Processing\nA main part of the backend is the report processing. It is not implemented in a class-based structure, but rather as a function. The report processing is started when a user uploads an annual report in the frontend. The frontend sends the annual report to the backend. As the processing of the annual report can take a long time depending on the length of the report, the processing is done in the background using the FastAPI BackgroundTasks feature. The frontend receives a response from the backend that contains a job-id. The frontend can then use this job-id to query the backend for the status of the processing job.\n\nStoring the uploaded report and starting the processing\nWhile the RAG-Pipeline doesn’t require the original report once it is processed, we store the original file for the frontend pdf viewer. The Docker container mounts a volume to the /backend/filestore directory, where the original reports are stored. The following code snippet shows how the report is stored and the processing is started:\n@router.post(\"/ingest\")\nasync def ingest_file(background_tasks: BackgroundTasks,\n                      file: UploadFile = File(...),\n                      report_public: bool = False,\n                      user=Security(verify_token.verify_token)):\n\n    # Creates report_id for file storage and report folder\n    report_id = str(uuid.uuid4())\n    if not os.path.exists(f\"./filestore/{report_id}\"):\n        os.makedirs(f\"./filestore/{report_id}\")\n\n    # Stores the file to the filestore\n    with open(f'./filestore/{report_id}/{file.filename}', \"wb\") as buffer:\n        shutil.copyfileobj(file.file, buffer)\n\n    # Extracts metadata from the file\n    file_metadata = process_file_metadata(report_id, f'./filestore/{report_id}/{file.filename}')\n\n    # Initialises database session and loads the user object\n    session = config.mysql_db.get_session()\n    user = session.query(User).filter_by(user_id=user.user_id).first()\n\n    ...\n\n    # Creates a new report object and adds it to the database\n    report = Report(report_id=report_id,\n                    filename=file.filename,\n                    title=file_metadata[\"document_title\"],\n                    company_id=company.company_id,\n                    year=file_metadata[\"report_year\"],\n                    report_public=report_public)\n    session.add(report)\n    if user and report:\n        # Links the report to the user\n        user.reports.append(report)\n        session.commit()\n\n    # Creates the processing job and adds it to the database\n    job = Job(job_id=str(uuid.uuid4()),\n              object_id=report.report_id,\n              object_type=\"Report\",\n              status=\"Pending\")\n    session.add(job)\n    session.commit()\n\n    # Initiates background task to process file\n    background_tasks.add_task(process_file,\n                              job_id=job.job_id,\n                              filename=f'./filestore/{report_id}/{file.filename}',\n                              report_id=report.report_id)\n\n    return {\"task_id\": job.job_id, \"message\": job.status}\n\n\nProcessing the report\nThe processing of the report is don by the process_file function. The function is started as a background task and then runs the report through two steps. In the first step, we identify and extract all the tables from the report. It should be noted that the extraction of the table does not mean that the content of the table is extracted. It only means that the backend knows that there is a table in the report and that table needs to be processed at a later stage. The second step is the extraction of the text from the report. The text is then chunked, embedded and stored in the Chroma Vector Store. The following code snippet shows sections of the process_file function:\ndef process_file(job_id, filename, report_id):\n    # Sets job status to processing\n    job = session.query(Job).filter(Job.job_id == job_id).first()\n    job.status = \"Processing\"\n    job.percentage = 0\n    session.commit()\n\n    # Defines the document splitter and embedding function\n    splitter = RecursiveCharacterTextSplitter(\n        chunk_size=900,\n        chunk_overlap=50,\n        separators=[\"\\n\\n\", \"(?&lt;=\\. )\"],\n        length_function=len\n    )\n\n    embedding_function = embedding_functions.OpenAIEmbeddingFunction(\n        api_key=config.OPENAI_API_KEY,\n        model_name=config.EMBEDDING_MODEL_NAME\n    )\n\n    # Extracts tables from the report\n    extract_tables(filename, job.object_id)\n\n    # Load the report and extract the text\n    loader = PyPDFLoader(filename)\n    pages = loader.load()\n    docs = splitter.split_documents(pages)\n    total_docs = len(docs)\n    for index, doc in enumerate(docs):\n        try:\n            # Create Meta-Data for the document\n            meta_data = {\n                \"filename\": filename,\n                \"doc_type\": \"Report\",\n                \"report_id\": report_id,\n                \"page_number\": doc.metadata[\"page\"],\n            }\n            new_uuid = uuid.uuid4()\n\n            # Embed the document and store it in the Chroma Vector Store\n            collection.add(\n                ids=[str(new_uuid)],\n                documents=doc.page_content,\n                metadatas=meta_data)\n\n            # Update the job status\n            job.percentage = (index + 1) / total_docs * 100\n            session.commit()\n        except Exception as e:\n            ...\n    job.status = \"Completed\"\n        session.commit()\n        session.close()\n\n\nProcessing the tables\nThe extraction of the tables from the report is done by the extract_tables function. This function creates a new job for every table that is extracted from the report. While we could have implemented a queuing system for processing open jobs, we decided to keep the system simple and work with FastAPIs BackgroundScheduler and utilize the Jobs entity of our data model.\nThe BackgroundScheduler calls the process_table function every 2 minutes, which checks if there are any open jobs for processing tables. If there are, the process_table function retrieves the next two open jobs and processes them. The following code snippet shows how we registered the BackgroundScheduler in the lifecycle of the FastAPI application:\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Function that handles the startup and shutdown of the application\"\"\"\n    config = Config()\n    scheduler = BackgroundScheduler()\n    scheduler.add_job(process_tables, 'interval', minutes=2)\n    scheduler.start()\n    yield\n    print(\"Shutting down\")\n    scheduler.shutdown()\nThe process of extracting the tables from the report as well as the extraction of the content of the tables is not shown in this section of the documentation, as it covered in the RAG-Pipeline documentation. The full code can be found in the process_file and analyse_table functions in the backend.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Backend Implementation</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/GoogleAuth.html",
    "href": "BackendArchitecture/GoogleAuth.html",
    "title": "Authentication with Google",
    "section": "",
    "text": "Process flow of the authentication\nThis user object now contains all the important information that is displayed on the start page and in the navigation bar, among other things, and the token that is sent with every backend request. On the backend side, we force the JWT token to be sent in the header when an endpoint is called, otherwise it is not even possible to execute the called function.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Authentication with Google</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/GoogleAuth.html#process-flow-of-the-authentication",
    "href": "BackendArchitecture/GoogleAuth.html#process-flow-of-the-authentication",
    "title": "Authentication with Google",
    "section": "",
    "text": "User logs in by clicking the button\nGoogle returns JWT\nSends JWT to the backend\nBackend checks whether the user exists in our DB in the “user” table\nIf not, a user is created in the DB and the user object is sent to the frontend, if yes, this user object is sent to the frontend\nIn the frontend, a separate user object is created in the session memory, which contains both the data sent by the DB (userName and userId) and data directly from the JWT (firstName, lastName, profilePictureUrl), as well as the JWT itself. The data that we extract directly from the JWT in the frontend is not stored in the DB, which is why it is not contained in the user object that comes from the DB.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Authentication with Google</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/GoogleAuth.html#frontend-fetching-function",
    "href": "BackendArchitecture/GoogleAuth.html#frontend-fetching-function",
    "title": "Authentication with Google",
    "section": "Frontend fetching function",
    "text": "Frontend fetching function\nFor this reason, we have created a function in the frontend that writes the JWT in the HTML header of each request. This function is used for all of our backend requests and therefore also offers additional parameters so that it can be used flexibly for any type of request. These include the mandatory specification of the CRUD method (Create, Read, Update, Delete) and the optional specification of a body. However, the latter is only used when uploading the annual report. In the event that the backend returns an error code or nothing at all, we have error handling in the frontend. Sometimes the error is only displayed on the browser console, but sometimes it is also displayed in the frontend, e.g. if you try to load a non-existent analysis. In any case, however, an error message in the backend does not cause the frontend to crash, as we are informed by Typescript of the possibility of an empty response and accordingly functions that would have accessed data from the response are not even executed.\n\n\n\nFrontend fetching function",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Authentication with Google</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/GoogleAuth.html#backend-token-validation",
    "href": "BackendArchitecture/GoogleAuth.html#backend-token-validation",
    "title": "Authentication with Google",
    "section": "Backend token validation",
    "text": "Backend token validation\nOn the backend side, this looks like this in the API. We have given each endpoint that is to be protected the attachment user=Security(verify_token.verify_token). This ensures that a token must always be passed when the function is called via the endpoint.\n\n\n\nBackend Endpoint requires user token\n\n\nTo validate the token, it is first extracted from the header and then sent to Google via an interface for verifying so-called oauth2 tokens, which report back to us whether this token is valid or not.\n\n\n\nBackend verify user token\n\n\nAfter this, the database is checked to see whether or not the user already exists. The user object is then sent back.\n\n\n\nCheck if the user exists in DB\n\n\nThis individual access includes access to the public reports and to all private reports uploaded by the user. In addition, each user can create their own SWOT analysis for each of their reports and create a SWOT comparison between two different reports.\n\n\n\nFrontend fetching function\nBackend Endpoint requires user token\nBackend verify user token\nCheck if the user exists in DB",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Authentication with Google</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/API.html",
    "href": "BackendArchitecture/API.html",
    "title": "REST API",
    "section": "",
    "text": "Architecture\nIn our system, we have created a separate endpoint in the API for each function that is required in the front end, which can be used to access this function. The functions are divided into different routes for the sake of clarity. These are System Services, Chat Services (Experimental), File Services and SWOT Analysis. Each of these routes then has one or more end points that we can call via this address in combination with the CRUD method. To add a new endpoint, we simply need to create a new one as shown here. It is also important to note that we have kept the API and the logic very strictly separate. All functions that are more extensive than a simple DB access are outsourced to other files and are only called in the API.",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>REST API</span>"
    ]
  },
  {
    "objectID": "BackendArchitecture/API.html#architecture",
    "href": "BackendArchitecture/API.html#architecture",
    "title": "REST API",
    "section": "",
    "text": "@app.get(\"/\")\nasync def root():\n    \"\"\"Test DB-Status\"\"\"\n    config = Config()\n    if config.db.collection.peek() is not None:\n        return {'status': 'ok'}\n    else:\n        return {'status': 'error'}\n\nSystem Services\nPath: /system/v1\nInfo: For more information have a look in the Code-File /routers/system.py\n/login: This function is called to log in the user. In case the user doesn’t exist in the DB, it is created.\n\n\nChat Services (Experimental)\nPath: /chat/v1\nInfo: For more information have a look in the Code-File /routers/chat.py\n/advanced_qa: Answer questions about the reports\n\n\nFile Services\nPath: /files/v1\nInfo: For more information have a look in the Code-File /routers/file.py\n/ingest: Starts the ingestion of the file to the database and returns the task id\n/status/{task_id}: Obtain the processing status of a recently uploaded file.\n/uploaded_reports: Get all reports the user has access to\n/delete_report: Remove a report from the database\n/pdf_file: Get pdf file from the database\n/analyse/table: Creates embeddings for the table screenshots from the annual reports\n\n\nSWOT Analysis\nPath: /swot/v1\nInfo: For more information have a look in the Code-File /routers/swot.py\n/swot/{report_id}: List available swot analysis\n/swot/{report_id}/{analysis_id}: Get a specific swot analysis from the database\n/swot/{report_id}: Create a new swot analysis to a given report\n/swot/{report_id}/vs/{compare_report_id}: Get a specific swot analysis comparison from the database\n/swot/{report_id}/vs/{compare_report_id}: Create a new swot analysis comparison for two given reports\n/latestAnalysis: Retrieve the latest SWOT analysis form the database for a given report\n\n\ndefault\nPath: /\nInfo: For more information have a look in the Code-File /main.py\n/: Test DB-Status\n/test_backend_connection: Test Backend-Status",
    "crumbs": [
      "Backend",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>REST API</span>"
    ]
  },
  {
    "objectID": "Frontend/FrontendIntro.html",
    "href": "Frontend/FrontendIntro.html",
    "title": "Frontend Documentation",
    "section": "",
    "text": "Overview of the frontend functionalities:",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Frontend Documentation</span>"
    ]
  },
  {
    "objectID": "Frontend/FrontendIntro.html#overview-of-the-frontend-functionalities",
    "href": "Frontend/FrontendIntro.html#overview-of-the-frontend-functionalities",
    "title": "Frontend Documentation",
    "section": "",
    "text": "Login and access to backend functions:\n\nRegistered users have the opportunity to use all functions of our backend. These include uploading annual reports and interacting with the RAG pipeline.\n\nAnnual report processing:\n\nOnce an annual report has been uploaded, it is sent to our backend. There it passes through the RAG pipeline as described on the Page RAG pipeline.\nIn the second step, the processed report can be used to create a SWOT analysis in the frontend.\n\nSWOT analysis generation:\n\nUsers can generate and display a SWOT analysis in the frontend.\nThe basis for this is the processed annual report from the backend.\n\nComparison of annual reports:\n\nIn addition to the individual analysis, our system offers the option of comparing analyses of two annual reports.\nUsers can view the results of these comparisons in the front end.\n\nChatbot support:\n\nWe have implemented a chatbot that allows users to ask self-formulated questions about a selected annual report.\nThe chatbot offers an interactive way of requesting information and makes it easier to navigate the system.\n\n\n\n\n\nWelcome page of StratMystiqPro\n\n\n\n\n\nWelcome page of StratMystiqPro",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Frontend Documentation</span>"
    ]
  },
  {
    "objectID": "Frontend/Techstack.html",
    "href": "Frontend/Techstack.html",
    "title": "Frontend Techstack",
    "section": "",
    "text": "React\nThe choice to use React as a frontend instead of other web frontends, some of which are based on Python, was made because it allows us to use and style individual components, making our UI more adaptable to the use case and, in particular, to the subsequent users described in the personas. We have also already had good experience with React in the past, which we were happy to expand on in this project. Another reason is that, compared to the other frameworks tested, Streamlib and Gradio, user authentication via Google Login was much easier to implement here.",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Frontend Techstack</span>"
    ]
  },
  {
    "objectID": "Frontend/Techstack.html#vite",
    "href": "Frontend/Techstack.html#vite",
    "title": "Frontend Techstack",
    "section": "Vite",
    "text": "Vite\nWe also opted for Vite as a development server for React, as it offers several advantages in terms of building times and ease of development. In addition to a much faster server startup time and building time for deployment, rebuilding when changing the code during development also takes place with almost no waiting time. This becomes particularly important when the size of the project increases, but the difference is also very noticeable with a project of our size. This increase in performance is achieved by so-called native ESM (ECMAScript Module) and the Hot Module Replacement (HMR) that this enables. This means that individual parts of the application can be replaced during operation without having to reload the entire page if the code is changed and this component needs to be rebuilt. This also preserves the state of the page, which means, for example, that all entries made are not lost and it is not necessary to log back in with Google. (webpack n.d.) (Vite n.d.)",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Frontend Techstack</span>"
    ]
  },
  {
    "objectID": "Frontend/Techstack.html#typescript",
    "href": "Frontend/Techstack.html#typescript",
    "title": "Frontend Techstack",
    "section": "TypeScript",
    "text": "TypeScript\nFor the functional development of the frontend, we chose TypeScript as our programming language instead of typical JavaScript. It enables type-safe development by enforcing types and interfaces for all variables and the associated better error analysis.",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Frontend Techstack</span>"
    ]
  },
  {
    "objectID": "Frontend/Techstack.html#tailwindcss",
    "href": "Frontend/Techstack.html#tailwindcss",
    "title": "Frontend Techstack",
    "section": "TailwindCSS",
    "text": "TailwindCSS\nFor styling, we use the TailwindCSS framework, which combines typical CSS functions into classes that can be applied directly to the individual elements in the HTML code, similar to inline css. This makes styling easier for us and, from our point of view, makes it easier to maintain the code and keep it clearer, as the styling of the individual HTML elements is not outsourced to an external CSS file, but is implemented directly in the code where it is later used. It also makes it easy to create responsive designs.",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Frontend Techstack</span>"
    ]
  },
  {
    "objectID": "Frontend/Techstack.html#materialui",
    "href": "Frontend/Techstack.html#materialui",
    "title": "Frontend Techstack",
    "section": "MaterialUI",
    "text": "MaterialUI\nNevertheless, we used the MaterialUI component library for some components, as we did not have to create the elements ourselves. We used the framework of the dialog and dropdown component from MaterialUI for our popup and added our own content there. The advantage of this ready-made component is that it already has an animation for opening and closing, as well as a responsive design. Building this component ourselves would have taken some time and the result would have been about the same.",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Frontend Techstack</span>"
    ]
  },
  {
    "objectID": "Frontend/Techstack.html#eslint-and-prettier",
    "href": "Frontend/Techstack.html#eslint-and-prettier",
    "title": "Frontend Techstack",
    "section": "ESlint and Prettier",
    "text": "ESlint and Prettier\nWe also use the formatting and linting tools Prettier and ESLint to increase code quality. Prettier ensures that the code is in a uniform format. This means, for example, that all indentations, breaks and spaces in brackets are always consistent across all files. ESlint helps to analyze the code for errors and avoid bad coding style. For example, it throws a warning if the same code is found in multiple files and then suggests exporting it or warns if an attempt is made to access variables or functions that do not exist. Without this help, such an error would only become apparent at runtime and possibly cause the program to crash.",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Frontend Techstack</span>"
    ]
  },
  {
    "objectID": "Frontend/Techstack.html#google-single-sign-on",
    "href": "Frontend/Techstack.html#google-single-sign-on",
    "title": "Frontend Techstack",
    "section": "Google Single-Sign-on",
    "text": "Google Single-Sign-on\nAnother important library that we use in the frontend is that of the Google Single-Sign-on identity provider. Here we have the option of simple and reliable user authentication by requiring users to log in to our frontend with their Google account. We then identify the users via the JWT token returned by the identity provider by reading the ID it contains and comparing it with our database.\n\n\n\n\nVite. n.d. “Vite Features.” Accessed January 10, 2024. https://vitejs.dev/guide/features.html.\n\n\nwebpack. n.d. “Hot Module Replacement.” Accessed January 10, 2024. https://webpack.js.org/guides/hot-module-replacement/.",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Frontend Techstack</span>"
    ]
  },
  {
    "objectID": "Frontend/ux.html",
    "href": "Frontend/ux.html",
    "title": "User experience",
    "section": "",
    "text": "We have developed a logical user guidance for our frontend, in which the user is guided step by step through the process from uploading the PDF with the annual report to creating and viewing the finished SWOT analysis. (More in the User Guide)\nOverall, we have taken a minimalist approach to the design of the frontend. This means that we have made sure that we only have the most important elements on one page and arrange the individual elements in a recurring layout. Accordingly, the content of our pages is always centered and all text is left-aligned. For orientation, the navigation bar is always displayed at the top of the screen with the currently selected page highlighted. We also use only a few colors and a few gradations of them. Specifically, this is a dark blue as the background color, a lighter blue as the primary color, as well as gradations of it for all our elements and orange as an accent color, which we use for the buttons. We decided to use a dark background and a small number of colors to create a coherent and harmonious look and not distract the user from the content. We created this color combination using an online tool for creating color parallels and then adjusted it slightly. In addition, for reasons of readability and aesthetics, we use a shade of white as the text color to avoid too much contrast between the background and the text, which could otherwise lead to visual fatigue. (Albert 2016, pg. 60)\nWe have also deliberately decided to use rounded corners everywhere to create a softer look. In addition, all clickable elements are provided with a zoom effect or have a highlighted background as soon as you hover over them with the mouse so that they are even easier to recognize as such.\n\n\n\nFrontend Hover Text\n\n\n\n\n\nFrontend Hover Button\n\n\nFor reasons of accessibility, we have also made sure that the onClick functions are not placed on elements other than buttons, which also allows people with operating aids, such as a screen reader, to localize clickable elements.\nTo make it easier for users to use our tool and avoid unnecessary click paths, we automatically load the most recent analysis created by the user on the SWOT page when a report is selected, if one already exists. If no analysis has yet been created, we display a corresponding message at the top right of the screen to inform users that they must first create one. We also display such messages if the login has failed and if a new analysis is currently being generated, as this process takes some time.\n\n\n\nNo SWOT Analysis message\n\n\nDuring the upload and processing of a report, the progress is indicated by a loading bar. While the processing is running, the upload button is grayed out so that another report cannot be uploaded in the meantime.\n\n\n\nFrontend loading bar\n\n\n\n\n\nFrontend Hover Text\nFrontend Hover Button\nNo SWOT Analysis message\nFrontend loading bar\n\n\n\nAlbert, M. 2016. Besseres Mobile-App-Design: Optimale Usability Für iOS Und Android. entwickler.Press.",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>User experience</span>"
    ]
  },
  {
    "objectID": "Frontend/ComponentDesc.html",
    "href": "Frontend/ComponentDesc.html",
    "title": "Component description",
    "section": "",
    "text": "As is typical for React, we have built components for all our elements that we can reuse modularly elsewhere. We first planned and designed these components in Figma and then implemented them. Shown here is our first Figma design, which still contains a few things that we adjusted compared to the final implementation, such as the left orientation of the texts and elements, as well as the colors.\n\n\n\nPrimal Figma design of the upload page\n\n\n\n\n\nPrimal Figma design of the SWOT-Matrix\n\n\nOne example of this is the complete SWOT matrix, which is used on both the SWOT page and the comparison page. The same applies to the button component, which we use wherever the orange button is required. The two tables on the My Reports page are also based on the same component. This division of the individual elements into components makes it easier for us to assemble new elements from them without having to rebuild the respective components each time. All of them also have interfaces for adjusting individual parameters, such as color, text or, of course, if they display dynamic data from the database, a way to read it in. From a development point of view, a granular division into components makes sense above all if they can be reused in other elements and therefore do not have to be developed anew for each element. Above all, this saves time and also avoids malfunctions, as you don’t have to write functionally identical or similar code multiple times. You also don’t have to make sure that you implement the same design every time, as this is already specified by the component.\nWhen styling the components, we consistently developed and implemented a design adapted for smaller screens in addition to the normal design for large screens. The frontend was developed desktop first, i.e. we focused primarily on large screen sizes and only adapted the existing design for small screens in a second step. By individually adapting the components to the mobile design only when the available space makes it necessary, we have a seamless responsiveness that works on practically all common screen sizes.\n\n \n\n\n\n\nPrimal Figma design of the upload page\nPrimal Figma design of the SWOT-Matrix",
    "crumbs": [
      "Frontend",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Component description</span>"
    ]
  },
  {
    "objectID": "deployment.html",
    "href": "deployment.html",
    "title": "Deployment",
    "section": "",
    "text": "Set up the backend for local development:",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Deployment</span>"
    ]
  },
  {
    "objectID": "deployment.html#set-up-the-backend-for-local-development",
    "href": "deployment.html#set-up-the-backend-for-local-development",
    "title": "Deployment",
    "section": "",
    "text": "Ensure you have Python 3.11 or later installed.\nInstall the required dependencies with pip install -r requirements.txt.\nEnsure that you have Docker installed. Start it with using Docker Compose up\nEnsure the MySQL and Chroma databases are running. These can be started using Docker Compose with the command docker-compose up mysql chromadb.\nRun the application with python main.py.\nThe main.py script takes care of setting up the application. It creates the database tables if they don’t exist.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Deployment</span>"
    ]
  },
  {
    "objectID": "deployment.html#setup-for-the-frontend-for-local-development",
    "href": "deployment.html#setup-for-the-frontend-for-local-development",
    "title": "Deployment",
    "section": "SetUp for the frontend for local development:",
    "text": "SetUp for the frontend for local development:\n\nEnsure that you have Node.js and npm installed\nInstall the required dependencies with: npm install\nTo run the frontend you have to use npm run dev\nDuring the developmentnpm run tailwind needs to be started as well",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Deployment</span>"
    ]
  },
  {
    "objectID": "deployment.html#deployment-for-testing-and-production",
    "href": "deployment.html#deployment-for-testing-and-production",
    "title": "Deployment",
    "section": "Deployment for testing and production:",
    "text": "Deployment for testing and production:\nFor testing and production environments, we use Docker.\n\nEnsure you have Docker installed.\nCheck the Dockerfile and docker-compose.yaml files in the root directory of the project\nIf necessary, adjust the configuration in the Dockerfile and docker-compose.yaml files\nTo build and start the containers, use: docker-compose up –build\nThe application should now run in Docker containers and be accessible via the specified ports.\nMake sure that all services are configured correctly and the environment variables, if required, are adjusted in the docker-compose.yaml and .env files.\nRun the Docker container with docker-compose up.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Deployment</span>"
    ]
  },
  {
    "objectID": "userManual.html",
    "href": "userManual.html",
    "title": "User Manual",
    "section": "",
    "text": "1. First step: Log-in\nTo Log-in you are going to navigate form your Log-in screen to the Google-authentication field.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>User Manual</span>"
    ]
  },
  {
    "objectID": "userManual.html#nice-to-know",
    "href": "userManual.html#nice-to-know",
    "title": "User Manual",
    "section": "Nice to know:",
    "text": "Nice to know:\nWhen you click on the symbol of StratMystiqPro in the upper left corner you land on our HomePage. Here we give you a short description on what our tool does and how it works.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>User Manual</span>"
    ]
  },
  {
    "objectID": "userManual.html#second-step-upload-reports",
    "href": "userManual.html#second-step-upload-reports",
    "title": "User Manual",
    "section": "2. Second step: Upload reports",
    "text": "2. Second step: Upload reports\nAfter you successfully logged-in you should land on the MyReports-Page where you can upload reports and see which reports you already have uploaded.  To upload a new report you have to click the button Upload new Report.  Then you can either choose or drag and drop a file into the field.  Afterwards you decide between checking the checkbox so the report is available for every user or not checking the box so the report is only be available for you.  After you uploaded the report you can klick on the SWOT field, this will guide you directly to the SWOT Page. If you want to delete a report you can do so over the traschcan symbol on the right side.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>User Manual</span>"
    ]
  },
  {
    "objectID": "userManual.html#thrid-step-create-swot-analysis",
    "href": "userManual.html#thrid-step-create-swot-analysis",
    "title": "User Manual",
    "section": "3. Thrid step: Create SWOT-Analysis",
    "text": "3. Thrid step: Create SWOT-Analysis\n Through the dropdown-menu you can select a report from the uploaded reports. If you have already created a SWOT analysis for the selected report it will be automatically fetched from the database. Then you can see the summary first for each category:  If you then click into one of the four categories you will get a full description for every given point:  If you want to create a new SWOT-Analysis you can press the button Create SWOT.  If the system is creating the SWOT you will get a pop-up in the upper right croner with a message that the SWOT-Analysis will be created now.  After 5-6 minutes the SWOT-Analysis should be created and the summary should be visible in each category.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>User Manual</span>"
    ]
  },
  {
    "objectID": "userManual.html#fourth-step-create-comparison-swot-analysis.",
    "href": "userManual.html#fourth-step-create-comparison-swot-analysis.",
    "title": "User Manual",
    "section": "4. Fourth step: Create Comparison-SWOT-Analysis.",
    "text": "4. Fourth step: Create Comparison-SWOT-Analysis.\nNow you landed on the Compare Companies Page. Here you can compare two bussiness reports from different companies with each other.  For this you can select two different reports in the drop-down menus. The same principle applies here as for the SWOT analysis. If you already created a Comparison-SWOT it will be fetched automatically after you selected the corresponding reports. The differences in each category will be listed in summary version first.  Then you can click into one of the category to see the full desricption for each difference.  If you want to create a new Comparison-SWOT you can click the button Create SWOT Comparison after you selected two reports.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>User Manual</span>"
    ]
  },
  {
    "objectID": "userManual.html#fith-step-ask-the-chatbot-quastions-about-a-report.",
    "href": "userManual.html#fith-step-ask-the-chatbot-quastions-about-a-report.",
    "title": "User Manual",
    "section": "5. Fith step: Ask the ChatBot quastions about a report.",
    "text": "5. Fith step: Ask the ChatBot quastions about a report.\nOn the page Chatbot we created a Chatbot that is currently still work in progess and therefore an aplha version. The first thing you see is a disclaimer warning you that the Chatbot may give incorrect answers. You should be aware of this at any time you are using the Chatbot  The chatbot works the follwoing way: First you have to selecet a report that you have a question for. After this you can write the question in the text field and click send.  The system takes a few seconds to generate the answer so please be aware of this. Then you can see the answer to you question directly underneath it. The answer is based on the information given in the report.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>User Manual</span>"
    ]
  },
  {
    "objectID": "userManual.html#sixth-step-log-out",
    "href": "userManual.html#sixth-step-log-out",
    "title": "User Manual",
    "section": "6. Sixth step: Log-out",
    "text": "6. Sixth step: Log-out\nWhen you have finished your analysis, you can log out by clicking on the icon in the top right-hand corner. From there you will be redirected back to the login screen.",
    "crumbs": [
      "Usage",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>User Manual</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Albert, M. 2016. Besseres Mobile-App-Design: Optimale Usability Für\niOS Und Android. entwickler.Press.\n\n\nArora, Daman, Anush Kini, Sayak Ray Chowdhury, Nagarajan Natarajan,\nGaurav Sinha, and Amit Sharma. 2023. “Gar-Meets-Rag Paradigm for\nZero-Shot Information Retrieval.” https://doi.org/10.48550/ARXIV.2310.20158.\n\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi,\nYi Dai, et al. 2023. “Retrieval-Augmented Generation for Large\nLanguage Models: A Survey.” https://doi.org/10.48550/ARXIV.2312.10997.\n\n\nLewis, Patrick, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir\nKarpukhin, Naman Goyal, Heinrich Küttler, et al. 2020.\n“Retrieval-Augmented Generation for Knowledge-Intensive Nlp\nTasks.” https://doi.org/10.48550/ARXIV.2005.11401.\n\n\nLi, Huayang, Yixuan Su, Deng Cai, Yan Wang, and Lemao Liu. 2022.\n“A Survey on Retrieval-Augmented Text Generation.” https://doi.org/10.48550/ARXIV.2202.01110.\n\n\n“Metrics  Ragas.” n.d. Accessed\nFebruary 14, 2024. https://docs.ragas.io/en/stable/concepts/metrics/index.html#ragas-metrics.\n\n\n“RAG Triad -\nTruLens.” n.d. Accessed February 14, 2024. https://www.trulens.org/trulens_eval/core_concepts_rag_triad/.\n\n\nShuster, Kurt, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston.\n2021. “Retrieval Augmentation Reduces\nHallucination in Conversation.” In\nFindings of the Association for\nComputational Linguistics: EMNLP\n2021, 3784–3803. Punta Cana, Dominican Republic: Association for\nComputational Linguistics. https://doi.org/10.18653/v1/2021.findings-emnlp.320.\n\n\nVenable, John, Jan Pries-Heje, and Richard Baskerville. 2016.\n“FEDS: A Framework for\nEvaluation in Design Science\nResearch.” European Journal of Information\nSystems 25 (1): 77–89. https://doi.org/10.1057/ejis.2014.36.\n\n\nVite. n.d. “Vite Features.” Accessed January 10, 2024. https://vitejs.dev/guide/features.html.\n\n\nWang, Liang, Nan Yang, and Furu Wei. 2023. “Query2doc: Query\nExpansion with Large Language Models.” https://doi.org/10.48550/ARXIV.2303.07678.\n\n\nwebpack. n.d. “Hot Module Replacement.” Accessed January\n10, 2024. https://webpack.js.org/guides/hot-module-replacement/.",
    "crumbs": [
      "References"
    ]
  }
]